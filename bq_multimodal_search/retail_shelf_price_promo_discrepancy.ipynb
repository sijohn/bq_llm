{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e08c0279",
      "metadata": {
        "id": "e08c0279"
      },
      "source": [
        "# Retail Shelf: Price and Promotion Discrepancy Finder (BigQuery + Gemini)\n",
        "\n",
        "This notebook demonstrates how to detect pricing/promotion mismatches by combining:\n",
        "\n",
        "### What we‚Äôre solving\n",
        "Retailers run thousands of **price & promo** campaigns weekly. In-store execution often drifts from plan:\n",
        "- Wrong sign vs POS price (e.g., *2 f√∂r 30* but POS lists **29.95**).\n",
        "- Wrong item/brand under sign.\n",
        "- Outdated promo sign after expiry.\n",
        "- Mixed promos within one display.\n",
        "  \n",
        "We **combine**:\n",
        "1) **Image embeddings** of shelf photos (Gemini multimodal)  \n",
        "2) **Text embeddings** of structured product pricing/promotions  \n",
        "3) A **single natural-language query** (e.g., ‚Äúgurka 2 f√∂r 30‚Äù) to retrieve relevant **images + products**, parse the sign (‚Äú2 for 30‚Äù ‚Üí **15 SEK** each), and **flag discrepancies** by comparing against structured prices.\n",
        "\n",
        "üí° Tip: The simplest way to run this notebook is by uploading it directly into BigQuery Studio ‚Üí Notebooks. That‚Äôs where this workflow was developed and tested, so it should run seamlessly there."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416e1379",
      "metadata": {
        "id": "416e1379"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- Google Cloud project with BigQuery and Vertex AI APIs enabled\n",
        "- gcloud and bq CLIs installed and authenticated (gcloud auth login)\n",
        "- A GCS bucket for sample images\n",
        "- A CSV named pricing_promotions.csv (downloaded below)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e95d2d",
      "metadata": {
        "id": "23e95d2d"
      },
      "source": [
        "## 0) Environment variables (edit as needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf01192",
      "metadata": {
        "id": "fcf01192"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "PROJECT_ID = os.environ.get('PROJECT_ID', 'sm-gemini-playground')\n",
        "BQ_DATASET = os.environ.get('BQ_DATASET', 'retail_shelf')\n",
        "BQ_LOCATION = os.environ.get('BQ_LOCATION', 'US')\n",
        "CONN_ID = os.environ.get('CONN_ID', f'{BQ_LOCATION}.retail_shelf_conn_us')\n",
        "GCS_BUCKET = os.environ.get('GCS_BUCKET', 'sm-gemini-pg-retail-semantic')\n",
        "GCS_PREFIX_BASE = os.environ.get('GCS_PREFIX_BASE', 'retail_shelf')\n",
        "GCS_PREFIX_GLOB = f'{GCS_PREFIX_BASE}/*'\n",
        "\n",
        "OBJ_TABLE = os.environ.get('OBJ_TABLE', 'shelves')\n",
        "IMG_EMB_TABLE = os.environ.get('IMG_EMB_TABLE', 'shelf_embeddings')\n",
        "IMG_EMB_INDEX = os.environ.get('IMG_EMB_INDEX', 'idx_shelf_image_embeddings')\n",
        "TXT_MODEL = os.environ.get('TXT_MODEL', 'text_embedding_model')\n",
        "MM_MODEL = os.environ.get('MM_MODEL', 'multimodal_embedding_model')\n",
        "PRICING_TABLE = os.environ.get('PRICING_TABLE', 'pricing_promotions')\n",
        "PRICING_EMB_TABLE = os.environ.get('PRICING_EMB_TABLE', 'pricing_promotions_emb')\n",
        "PRICING_VEC_VIEW = os.environ.get('PRICING_VEC_VIEW', 'pricing_promotions_vec')\n",
        "\n",
        "print(PROJECT_ID, BQ_DATASET, BQ_LOCATION, CONN_ID)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440c3949",
      "metadata": {
        "id": "440c3949"
      },
      "outputs": [],
      "source": [
        "%env PROJECT_ID=$PROJECT_ID\n",
        "%env BQ_DATASET=$BQ_DATASET\n",
        "%env BQ_LOCATION=$BQ_LOCATION\n",
        "%env CONN_ID=$CONN_ID\n",
        "%env GCS_BUCKET=$GCS_BUCKET\n",
        "%env GCS_PREFIX_BASE=$GCS_PREFIX_BASE\n",
        "%env GCS_PREFIX_GLOB=$GCS_PREFIX_GLOB\n",
        "%env OBJ_TABLE=$OBJ_TABLE\n",
        "%env IMG_EMB_TABLE=$IMG_EMB_TABLE\n",
        "%env IMG_EMB_INDEX=$IMG_EMB_INDEX\n",
        "%env TXT_MODEL=$TXT_MODEL\n",
        "%env MM_MODEL=$MM_MODEL\n",
        "%env PRICING_TABLE=$PRICING_TABLE\n",
        "%env PRICING_EMB_TABLE=$PRICING_EMB_TABLE\n",
        "%env PRICING_VEC_VIEW=$PRICING_VEC_VIEW\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1868c45f",
      "metadata": {
        "id": "1868c45f"
      },
      "source": [
        "## 1) Create dataset and Cloud Resource connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f25efa",
      "metadata": {
        "id": "a3f25efa"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "bq --location=${BQ_LOCATION} --project_id=${PROJECT_ID} mk -d ${BQ_DATASET} || echo \"Dataset may already exist\"\n",
        "\n",
        "bq --project_id=${PROJECT_ID} mk --connection --location=${BQ_LOCATION} --connection_type=CLOUD_RESOURCE ${CONN_ID} || true\n",
        "\n",
        "bq show --connection --location=${BQ_LOCATION} ${PROJECT_ID}.${CONN_ID} || true\n",
        "\n",
        "# Grant required permissions to the BigQuery connection service account\n",
        "# Replace SERVICE_ACCOUNT with the \"serviceAccount:...\" shown in the bq show output above\n",
        "\n",
        "SERVICE_ACCOUNT=\"serviceAccount:YOUR-CONNECTION-SA from above output\"\n",
        "\n",
        "\n",
        "# Allow BigQuery connection SA to read from GCS\n",
        "gcloud storage buckets add-iam-policy-binding gs://$GCS_BUCKET \\\n",
        "  --member=\"$SERVICE_ACCOUNT\" \\\n",
        "  --role=\"roles/storage.objectViewer\" \\\n",
        "  --project=$PROJECT_ID || true\n",
        "\n",
        "# Allow BigQuery connection SA to call Vertex AI remote models\n",
        "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
        "  --member=\"$SERVICE_ACCOUNT\" \\\n",
        "  --role=\"roles/aiplatform.user\" || true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c65ab9b0",
      "metadata": {
        "id": "c65ab9b0"
      },
      "source": [
        "## 2) Copy demo images and CSV from GitHub\n",
        "\n",
        "- Images: https://github.com/sijohn/bq_llm/tree/main/bq_multimodal_search/images\n",
        "\n",
        "The images will be loaded to Google Cloud Storage Bucket and then to Bigquery Object Tables.\n",
        "\n",
        "- CSV: https://github.com/sijohn/bq_llm/blob/main/bq_multimodal_search/pricing_promotions.csv\n",
        "\n",
        "The CSV file will be used to create pricing data table in Bigquery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f5ba7b",
      "metadata": {
        "id": "94f5ba7b"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "if [ -d bq_llm ]; then (cd bq_llm && git pull --ff-only); else git clone https://github.com/sijohn/bq_llm.git; fi\n",
        "gsutil -m cp -r bq_llm/bq_multimodal_search/images/* gs://${GCS_BUCKET}/${GCS_PREFIX_BASE}/\n",
        "\n",
        "curl -L -o pricing_promotions.csv https://raw.githubusercontent.com/sijohn/bq_llm/main/bq_multimodal_search/pricing_promotions.csv\n",
        "\n",
        "bq --location=${BQ_LOCATION} --project_id=${PROJECT_ID} load \\\n",
        "  --replace --autodetect --source_format=CSV --skip_leading_rows=1 \\\n",
        "  ${BQ_DATASET}.${PRICING_TABLE} ./pricing_promotions.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)"
      ],
      "metadata": {
        "id": "o4uHG95dptPA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1758581943918,
          "user_tz": -120,
          "elapsed": 3259,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "o4uHG95dptPA",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3bcf294",
      "metadata": {
        "id": "f3bcf294"
      },
      "source": [
        "## 3) Create Object Table over images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{PROJECT_ID}.{BQ_DATASET}.{OBJ_TABLE}`\n",
        "WITH CONNECTION `{PROJECT_ID}.{CONN_ID}`\n",
        "OPTIONS ( object_metadata = 'SIMPLE', uris = ['gs://{GCS_BUCKET}/{GCS_PREFIX_GLOB}'] );\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Object Table created:\", f\"{PROJECT_ID}.{BQ_DATASET}.shelves_v2\")"
      ],
      "metadata": {
        "id": "_FPFTxi6qu7T"
      },
      "id": "_FPFTxi6qu7T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "409fac91",
      "metadata": {
        "id": "409fac91"
      },
      "source": [
        "## 4) Create multimodal embedding model and generate image embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{CONN_ID}`\n",
        "OPTIONS ( endpoint = 'multimodalembedding@001' );\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Remote model created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}\")"
      ],
      "metadata": {
        "id": "D1Tzqm3CphGi"
      },
      "id": "D1Tzqm3CphGi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}` AS\n",
        "SELECT * FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}`,\n",
        "  TABLE `{PROJECT_ID}.{BQ_DATASET}.{OBJ_TABLE}`,\n",
        "  STRUCT(TRUE AS flatten_json_output)\n",
        ");\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Embedding Table created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zgaRHz4erfNi"
      },
      "id": "zgaRHz4erfNi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ea86cd9",
      "metadata": {
        "id": "1ea86cd9"
      },
      "source": [
        "## 5) Create a vector index for image embeddings (Optional)\n",
        "Not needed if the sample image set is less than 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55d0cd1e",
      "metadata": {
        "id": "55d0cd1e"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE VECTOR INDEX `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_INDEX}`\n",
        "ON `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}` (ml_generate_embedding_result)\n",
        "OPTIONS ( index_type = 'IVF', distance_type = 'COSINE' );\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Index created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_INDEX}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485859ef",
      "metadata": {
        "id": "485859ef"
      },
      "source": [
        "## 6) Text embeddings for pricing table and a clean view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f34dd2",
      "metadata": {
        "id": "21f34dd2"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.{TXT_MODEL}`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{CONN_ID}`\n",
        "OPTIONS ( ENDPOINT = 'gemini-embedding-001' );\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Text Model created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{TXT_MODEL}\")\n",
        "\n",
        "\n",
        "\n",
        "sql = f'''\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{PRICING_EMB_TABLE}` AS\n",
        "SELECT * EXCEPT(content)\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{PROJECT_ID}.{BQ_DATASET}.{TXT_MODEL}`,\n",
        "  (\n",
        "    SELECT TRIM(CONCAT(\n",
        "      IFNULL(product_name,''), ' ', IFNULL(category,''), ' ', IFNULL(promo_text,''), ' ',\n",
        "      IFNULL(FORMAT('listed %.2f', listed_price), ''), ' ',\n",
        "      IFNULL(FORMAT('promo %.2f', promo_price), '')\n",
        "    )) AS content,\n",
        "    p.*\n",
        "    FROM `{PROJECT_ID}.{BQ_DATASET}.{PRICING_TABLE}` p\n",
        "  ),\n",
        "  STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)\n",
        ");\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Pricing Embedding Table created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{PRICING_EMB_TABLE}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sql = f'''\n",
        "CREATE OR REPLACE VIEW `{PROJECT_ID}.{BQ_DATASET}.{PRICING_VEC_VIEW}` AS\n",
        "SELECT * FROM `{PROJECT_ID}.{BQ_DATASET}.{PRICING_EMB_TABLE}`\n",
        "WHERE ARRAY_LENGTH(ml_generate_embedding_result) = 3072;\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Pricing View created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{PRICING_VEC_VIEW}\")\n"
      ],
      "metadata": {
        "id": "Cb8oIvujtBAy"
      },
      "id": "Cb8oIvujtBAy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33c5f931",
      "metadata": {
        "id": "33c5f931"
      },
      "source": [
        "## 7) Enable table display (Colab only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f012cc",
      "metadata": {
        "id": "49f012cc"
      },
      "outputs": [],
      "source": [
        "# @title Enable data table display (Colab only)\n",
        "import pandas as pd\n",
        "try:\n",
        "    %load_ext google.colab.data_table\n",
        "except Exception as e:\n",
        "    print('google.colab.data_table not available in this environment:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dc6b322d",
      "metadata": {
        "id": "dc6b322d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1758583613869,
          "user_tz": -120,
          "elapsed": 198,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# @title Util function to display images\n",
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def printImages(results):\n",
        "    image_results_list = list(results)\n",
        "    amt = len(image_results_list)\n",
        "    if amt == 0:\n",
        "        print('No rows to display.')\n",
        "        return\n",
        "    fig, axes = plt.subplots(nrows=amt, ncols=2, figsize=(20, max(4, amt*3)))\n",
        "    if amt == 1:\n",
        "        axes = [axes]\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    for i in range(amt):\n",
        "        gcs_uri = image_results_list[i][0]\n",
        "        text = str(image_results_list[i][1])\n",
        "        with tf.io.gfile.GFile(gcs_uri, 'rb') as f:\n",
        "            img = Image.open(io.BytesIO(f.read())).convert('RGB')\n",
        "        axes[i][0].axis('off')\n",
        "        axes[i][0].imshow(img)\n",
        "#         axes[i][0].set_title(gcs_uri, fontsize=8)\n",
        "        axes[i][1].axis('off')\n",
        "        axes[i][1].text(0, 0, text, fontsize=10, wrap=True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf15437d",
      "metadata": {
        "id": "bf15437d"
      },
      "source": [
        "## 7) Example image searches (natural language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242774a3",
      "metadata": {
        "id": "242774a3"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "DECLARE q STRING DEFAULT 'lindt chocolate bars';\n",
        "WITH query_vec AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}`,\n",
        "    (SELECT q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output)\n",
        "  )\n",
        ")\n",
        "SELECT base.uri,base.content_type\n",
        "FROM VECTOR_SEARCH(\n",
        "  TABLE `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}`, 'ml_generate_embedding_result',\n",
        "  TABLE query_vec, query_column_to_search => 'qvec', top_k => 5, distance_type => 'COSINE'\n",
        ");\n",
        "'''\n",
        "job = client.query(sql)\n",
        "res = job.result()\n",
        "printImages(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c767461",
      "metadata": {
        "id": "8c767461"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "DECLARE q STRING DEFAULT 'cucumbers (gurka) 2 for 30';\n",
        "WITH query_vec AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}`,\n",
        "    (SELECT q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output)\n",
        "  )\n",
        ")\n",
        "SELECT base.uri,base.content_type\n",
        "FROM VECTOR_SEARCH(\n",
        "  TABLE `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}`, 'ml_generate_embedding_result',\n",
        "  TABLE query_vec, query_column_to_search => 'qvec', top_k => 5, distance_type => 'COSINE'\n",
        ");\n",
        "'''\n",
        "job = client.query(sql)\n",
        "res = job.result()\n",
        "printImages(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57589b61",
      "metadata": {
        "id": "57589b61"
      },
      "source": [
        "## 8) Demo : Finding Price discrepency\n",
        "\n",
        "PS: Solution is not perfect. A more robust solution idea is presented in the next section. The challenge is here is to find a perfect join condition of Pricing data (product name) with the object table URI data which doesn't have a correct correlation to product name. Using RAG we can find almost close match, but not 1 to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fe8fea",
      "metadata": {
        "id": "f7fe8fea"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "-- Natural query typed ONCE by the auditor (passed as @q)\n",
        "DECLARE q STRING DEFAULT 'Lindt chocolate with price discrepancy';\n",
        "\n",
        "-- Parse \"N for X\" and compute per-unit sign price\n",
        "DECLARE n INT64        DEFAULT CAST(IFNULL(REGEXP_EXTRACT(q, r'(\\\\d+)\\\\s*for'), '1') AS INT64);\n",
        "DECLARE bundle FLOAT64 DEFAULT CAST(REGEXP_EXTRACT(q, r'for\\\\s*(\\\\d{{2,3}})') AS FLOAT64);\n",
        "DECLARE sign_each_price FLOAT64 DEFAULT SAFE_DIVIDE(bundle, n);\n",
        "\n",
        "WITH\n",
        "img_q AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.{MM_MODEL}`,\n",
        "    (SELECT q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output)\n",
        "  )\n",
        "),\n",
        "txt_q AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.{TXT_MODEL}`,\n",
        "    (SELECT q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_QUERY' AS task_type)\n",
        "  )\n",
        "),\n",
        "\n",
        "-- 1) Top image hits\n",
        "img_hits AS (\n",
        "  SELECT base.uri, distance AS img_distance\n",
        "  FROM VECTOR_SEARCH(\n",
        "    TABLE `{PROJECT_ID}.{BQ_DATASET}.{IMG_EMB_TABLE}`, 'ml_generate_embedding_result',\n",
        "    TABLE img_q, query_column_to_search => 'qvec',\n",
        "    top_k => 10, distance_type => 'COSINE'\n",
        "  )\n",
        "),\n",
        "\n",
        "-- 2) Product hits from structured table using TEXT embeddings\n",
        "prod_hits AS (\n",
        "  SELECT\n",
        "    base.* EXCEPT (ml_generate_embedding_result),\n",
        "    distance AS txt_distance\n",
        "  FROM VECTOR_SEARCH(\n",
        "    TABLE `{PROJECT_ID}.{BQ_DATASET}.{PRICING_EMB_TABLE}`, 'ml_generate_embedding_result',\n",
        "    TABLE txt_q, query_column_to_search => 'qvec',\n",
        "    top_k => 50, distance_type => 'COSINE'\n",
        "  )\n",
        ")\n",
        "\n",
        "-- 3) Present: top images + best-matching products with discrepancy signals\n",
        "SELECT\n",
        "  ARRAY_TO_STRING(\n",
        "    ARRAY(SELECT uri FROM img_hits ORDER BY img_distance LIMIT 3),\n",
        "    '\\\\n'\n",
        "  ) AS top_image_uris,\n",
        "  q AS auditor_query,\n",
        "  sign_each_price,\n",
        "  product_name,\n",
        "  category,\n",
        "  listed_price,\n",
        "  promo_text,\n",
        "  promo_price,\n",
        "  discrepancy_flag,\n",
        "  ROUND(ABS(listed_price - sign_each_price), 2) AS delta_vs_sign_listed,\n",
        "  ROUND(ABS(promo_price  - sign_each_price), 2) AS delta_vs_sign_promo,\n",
        "  txt_distance\n",
        "FROM prod_hits\n",
        "ORDER BY delta_vs_sign_listed DESC, txt_distance\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "job = client.query(sql)\n",
        "res = job.result()\n",
        "res.to_dataframe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept: Using RAG with Image & Pricing Data"
      ],
      "metadata": {
        "id": "eAECA2aKUOB6"
      },
      "id": "eAECA2aKUOB6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this hackathon demo we solved the problem using separate queries: one over the image object table (shelf embeddings) and one over the pricing/promotions table (text embeddings). A more robust approach for production would be to treat these two corpora as a RAG engine:\n",
        "\n",
        "\n",
        "1. Image results (URIs + embeddings) ‚Üí give us the candidate shelf photos.\n",
        "2. Pricing & promotion results (structured text embeddings) ‚Üí give us the expected product/pricing context.\n",
        "3. Auditor query ‚Üí feeds into both searches, and the top results from each are passed together into an AI model.\n",
        "\n",
        "The AI is then prompted with:\n",
        "\n",
        "System instruction (e.g., \"Compare shelf sign prices vs. promotion table\"),\n",
        "\n",
        "Top product rows from the structured table,\n",
        "\n",
        "URIs of the retrieved shelf images.\n",
        "\n",
        "This workflow allows the AI to directly cross-check what‚Äôs written on the shelf tag vs. what‚Äôs stored in the pricing system and produce a structured discrepancy report. While out of scope for this hackathon, this is the realistic end-to-end pipeline and can be implemented easily by lifting the query results into a RAG-style orchestrator."
      ],
      "metadata": {
        "id": "zD4NkxeKR8Vf"
      },
      "id": "zD4NkxeKR8Vf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Improvement Idea\n",
        "\n",
        "BigQuery today exposes AI.GENERATE for text generation. A natural next step would be a function like AI.COMPARE or a multimodal-enabled AI.PROMPT, where we can pass:\n",
        "\n",
        "* System instruction (comparison logic),\n",
        "* Multimodal input (URIs/images),\n",
        "* Structured table results (pricing/promotions).\n",
        "\n",
        "This would let us issue a single function call inside BigQuery that directly answers:\n",
        "üëâ ‚ÄúWhat does the price tag in this shelf image say, and does it match the promotion table record?‚Äù\n",
        "\n",
        "Such a feature would unify retrieval + multimodal prompting + structured output in one step, making discrepancy detection a first-class citizen in SQL workflows."
      ],
      "metadata": {
        "id": "4524u3XtUu0N"
      },
      "id": "4524u3XtUu0N"
    },
    {
      "cell_type": "markdown",
      "id": "b2c42caf",
      "metadata": {
        "id": "b2c42caf"
      },
      "source": [
        "## 13) Wrap up\n",
        "\n",
        "- No manual image-to-product tagging\n",
        "- Natural language powers both image and product retrieval\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}