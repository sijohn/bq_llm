{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "PQrK9TGY1PCp",
      "metadata": {
        "id": "PQrK9TGY1PCp"
      },
      "source": [
        "# Semantic Hybrid Search on Used Car Listings with BigQuery Vector Search\n",
        "\n",
        "In this notebook, we will explore on how to build a semantic search system using BigQuery Vector DB with the Vector Index (optional) feature, leveraging the gemini-embedding-001 model for embeddings. We'll use the Used Car Sales Listings dataset from Kaggle, loaded into BigQuery as the table.\n",
        "We will explore the use of task_type in the Gemini Embedding Model\n",
        "\n",
        " 1. RETRIEVAL_DOCUMENT: Use this when creating embeddings for the text you want to search over (our car listings). It optimizes the vectors to be effectively \"found\" in a search.\n",
        " 2. RETRIEVAL_QUERY: Use this when creating an embedding for the user's search query itself. It optimizes the vector for finding matching documents.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Load the Kaggle `used_car_listings.csv` into BigQuery (CLI cell). The CSV is available in the git repo where this notebook is shared\n",
        "2. Build a consolidated search base table (`content` column).\n",
        "3. Create a BigQuery **connection** to Vertex AI and a **remote model** for embeddings.\n",
        "4. Generate embeddings with `gemini-embedding-001`.\n",
        "5. (Optional) Create a Vector Index (IVF) on the embedding column.\n",
        "6. Run semantic queries using natural language.\n",
        "\n",
        "**Notes**\n",
        "- Use a region where BigQuery and Vertex AI are both available (e.g. `europe-north1`, `us-central1` or multiregion like `US` or `EU`).\n",
        "- Vector index creation requires sufficient data; very small tables (<~5k rows) may not allow an index.\n",
        "\n",
        "💡 Tip: The simplest way to run this notebook is by uploading it directly into BigQuery Studio → Notebooks. That’s where this workflow was developed and tested, so it should run seamlessly there.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V8FLYiLj1PCq",
      "metadata": {
        "id": "V8FLYiLj1PCq"
      },
      "source": [
        "## Prerequisites\n",
        "- Google Cloud project with **BigQuery** and **Vertex AI** APIs enabled.\n",
        "- You have the CSV locally or in Cloud Storage.\n",
        "- `gcloud` and `bq` CLIs installed and authenticated (`gcloud auth login`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ylG5mbw1PCs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 998,
          "status": "ok",
          "timestamp": 1758534958122,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "3ylG5mbw1PCs",
        "outputId": "a5c6e576-1997-4816-cbf4-4513ac718d51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "PROJECT_ID = os.environ.get('PROJECT_ID', 'your-project-id')\n",
        "BQ_DATASET = os.environ.get('BQ_DATASET', \"used_cars\")\n",
        "BQ_LOCATION = os.environ.get('BQ_LOCATION', 'europe-north1')  # match your dataset region\n",
        "CONN_ID = os.environ.get('CONN_ID', f'vertex_ai_conn_{BQ_LOCATION}')\n",
        "TABLE_SRC = 'used_cars_listing'   # raw CSV destination\n",
        "TABLE_BASE = 'used_cars_search_base'\n",
        "TABLE_EMB = 'used_cars_search'\n",
        "REMOTE_MODEL = 'text_embedding_model'\n",
        "print(PROJECT_ID, BQ_DATASET, BQ_LOCATION, CONN_ID)\n",
        "\n",
        "%env PROJECT_ID=$PROJECT_ID\n",
        "%env BQ_DATASET=$BQ_DATASET\n",
        "%env BQ_LOCATION=$BQ_LOCATION\n",
        "%env CONN_ID=$CONN_ID\n",
        "%env TABLE_SRC=$TABLE_SRC\n",
        "%env TABLE_BASE=$TABLE_BASE\n",
        "%env TABLE_EMB=$TABLE_EMB\n",
        "%env REMOTE_MODEL=$REMOTE_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HliNVTcU1PCs",
      "metadata": {
        "id": "HliNVTcU1PCs",
        "outputId": "59f8c28c-e9c5-47f4-c162-5203c12eadea",
        "tags": [
          "bash"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "PROJECT_ID=$PROJECT_ID}\n",
        "BQ_DATASET=${BQ_DATASET}\n",
        "BQ_LOCATION=${BQ_LOCATION}\n",
        "\n",
        "bq --location=${BQ_LOCATION} --project_id=${PROJECT_ID} mk -d --default_table_expiration 0 ${BQ_DATASET} || echo \"Dataset may already exist\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfgdrq41PCs",
      "metadata": {
        "id": "5cfgdrq41PCs"
      },
      "source": [
        "## 1) Load CSV into BigQuery\n",
        "If your file is local in the notebook environment, first upload it to Cloud Storage or use the Web UI.\n",
        "If it's already in your local machine, use the `bq load` command from a terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fDRmHcmR1PCs",
      "metadata": {
        "id": "fDRmHcmR1PCs",
        "tags": [
          "bash"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Example: load from local file path (run where the CSV is present):\n",
        "# bq --location=${BQ_LOCATION} --project_id=${PROJECT_ID} load \\\n",
        "#   --autodetect --source_format=CSV --skip_leading_rows=1 \\\n",
        "#   ${BQ_DATASET}.${TABLE_SRC} ./used_car_listings.csv\n",
        "echo \"Use the above command in a terminal with the CSV present.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uDuM3AE91PCt",
      "metadata": {
        "id": "uDuM3AE91PCt"
      },
      "source": [
        "## 2) Create a consolidated search base table\n",
        "We merge key attributes into a single `content` string which improves the quality of embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opaSUqjM1PCt",
      "metadata": {
        "id": "opaSUqjM1PCt"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
        "sql = f'''\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{TABLE_BASE}` AS\n",
        "SELECT\n",
        "  listing_id,\n",
        "  vin,\n",
        "  make,\n",
        "  model,\n",
        "  year,\n",
        "  trim,\n",
        "  body_type,\n",
        "  fuel_type,\n",
        "  transmission,\n",
        "  mileage,\n",
        "  price,\n",
        "  condition,\n",
        "  location,\n",
        "  seller_type,\n",
        "  features,\n",
        "  ARRAY_TO_STRING([\n",
        "    make,\n",
        "    model,\n",
        "    CAST(year AS STRING),\n",
        "    trim,\n",
        "    body_type,\n",
        "    fuel_type,\n",
        "    transmission,\n",
        "    CONCAT('mileage ', CAST(mileage AS STRING)),\n",
        "    CONCAT('price ', CAST(price AS STRING)),\n",
        "    condition,\n",
        "    location,\n",
        "    seller_type,\n",
        "    features\n",
        "  ], ' ', '') AS content\n",
        "FROM `{PROJECT_ID}.{BQ_DATASET}.{TABLE_SRC}`;\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{TABLE_BASE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJeiVACX1PCt",
      "metadata": {
        "id": "BJeiVACX1PCt"
      },
      "source": [
        "## 3) Create BigQuery ↔ Vertex AI connection\n",
        "This is a one-time setup. Replace IDs as needed. If it already exists, the commands will no-op."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ZjhPKC1PCt",
      "metadata": {
        "id": "e5ZjhPKC1PCt",
        "tags": [
          "bash"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "PROJECT_ID=${PROJECT_ID:-your-project-id}\n",
        "BQ_LOCATION=${BQ_LOCATION:-europe-north1}\n",
        "CONN_ID=${CONN_ID:-vertex_ai_conn_europe-north1}\n",
        "\n",
        "bq mk --connection --location=${BQ_LOCATION} --project_id=${PROJECT_ID} \\\n",
        "  --connection_type=CLOUD_RESOURCE ${CONN_ID} || echo \"Connection may already exist\"\n",
        "\n",
        "echo \"Service account for the connection:\"\n",
        "bq show --connection ${PROJECT_ID}.${BQ_LOCATION}.${CONN_ID} | sed -n 's/.*serviceAccountId: \\(.*\\)/\\1/p' || true\n",
        "echo \"Grant this SA roles/aiplatform.user with gcloud if not yet granted.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y1XsmeS91PCt",
      "metadata": {
        "id": "y1XsmeS91PCt"
      },
      "source": [
        "## 4) Create a remote embedding model in BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UHgnJ9Z21PCt",
      "metadata": {
        "id": "UHgnJ9Z21PCt"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.{REMOTE_MODEL}`\n",
        "REMOTE WITH CONNECTION `{BQ_LOCATION}.{CONN_ID}`\n",
        "OPTIONS(ENDPOINT = 'gemini-embedding-001');\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Remote model created:\", f\"{PROJECT_ID}.{BQ_DATASET}.{REMOTE_MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "knfwrk-41PCt",
      "metadata": {
        "id": "knfwrk-41PCt"
      },
      "source": [
        "## 5) Generate embeddings for listings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0kQ8CRaO1PCt",
      "metadata": {
        "id": "0kQ8CRaO1PCt"
      },
      "outputs": [],
      "source": [
        "sql = f'''\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{TABLE_EMB}` AS\n",
        "SELECT\n",
        "  listing_id, make, model, year, price, location, condition, features,\n",
        "  content,\n",
        "  ml_generate_embedding_result AS embedding\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{PROJECT_ID}.{BQ_DATASET}.{REMOTE_MODEL}`,\n",
        "  TABLE `{PROJECT_ID}.{BQ_DATASET}.{TABLE_BASE}`,\n",
        "  STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)\n",
        ");\n",
        "'''\n",
        "job = client.query(sql)\n",
        "job.result()\n",
        "print(\"Embeddings table:\", f\"{PROJECT_ID}.{BQ_DATASET}.{TABLE_EMB}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JH3lnnVh1PCt",
      "metadata": {
        "id": "JH3lnnVh1PCt"
      },
      "source": [
        "## 6) (Optional) Create a Vector Index (IVF)\n",
        "If your table is small, this step may be skipped automatically with a handled error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NSYm7DBs1PCt",
      "metadata": {
        "id": "NSYm7DBs1PCt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    sql = f'''\n",
        "    CREATE OR REPLACE VECTOR INDEX idx_used_cars_embedding\n",
        "    ON `{PROJECT_ID}.{BQ_DATASET}.{TABLE_EMB}`(embedding)\n",
        "    STORING (listing_id, make, model, year, price, location, condition)\n",
        "    OPTIONS(\n",
        "      index_type = 'IVF',\n",
        "      distance_type = 'COSINE',\n",
        "      ivf_options = '{{\"num_lists\":2000}}'\n",
        "    );\n",
        "    '''\n",
        "    job = client.query(sql)\n",
        "    job.result()\n",
        "    print(\"Vector index created: idx_used_cars_embedding\")\n",
        "except Exception as e:\n",
        "    print(\"Skipping index (likely small table):\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R_Er1nnu1PCt",
      "metadata": {
        "id": "R_Er1nnu1PCt"
      },
      "source": [
        "## 7) Run semantic queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8mrwpys81PCt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5288,
          "status": "ok",
          "timestamp": 1758539091279,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "8mrwpys81PCt",
        "outputId": "33d37e0f-6c52-49aa-cc39-950779f3e55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 matching results.\n",
            "   listing_id           make     model  year    price  \\\n",
            "0         308  Mercedes-Benz   C-Class  2020  20773.0   \n",
            "1        1161            BMW  3 Series  2013   3131.0   \n",
            "2        1394            BMW  3 Series  2013   2713.0   \n",
            "3         394  Mercedes-Benz   E-Class  2017   7905.0   \n",
            "4         208           Audi        Q5  2020  11476.0   \n",
            "5        1859            BMW  5 Series  2018  10719.0   \n",
            "6          26            BMW  3 Series  2016   5229.0   \n",
            "7        2030            BMW  3 Series  2020  15650.0   \n",
            "8        1737     Volkswagen    Tiguan  2020  11120.0   \n",
            "9         717  Mercedes-Benz   C-Class  2008   1289.0   \n",
            "\n",
            "                       location  condition  \\\n",
            "0  Gräfenhainichen, RP, Germany  excellent   \n",
            "1           Lübben, TH, Germany       good   \n",
            "2           Lübeck, TH, Germany       good   \n",
            "3         Northeim, BE, Germany       good   \n",
            "4       Rudolstadt, NI, Germany  excellent   \n",
            "5   Donaueschingen, HH, Germany       good   \n",
            "6      Oranienburg, BB, Germany       good   \n",
            "7          South Johnny, NC, US       good   \n",
            "8         Eisenach, HH, Germany       good   \n",
            "9            Kusel, TH, Germany       good   \n",
            "\n",
            "                                            features  \\\n",
            "0  Adaptive Cruise Control, Android Auto, Backup ...   \n",
            "1  Alloy Wheels, Backup Camera, Heated Seats, LED...   \n",
            "2  Apple CarPlay, Blind Spot Monitor, Lane Keep A...   \n",
            "3  Adaptive Cruise Control, Alloy Wheels, Backup ...   \n",
            "4  Adaptive Cruise Control, Alloy Wheels, Backup ...   \n",
            "5  Adaptive Cruise Control, Android Auto, Blind S...   \n",
            "6                                               None   \n",
            "7  Adaptive Cruise Control, Android Auto, Backup ...   \n",
            "8  Android Auto, Blind Spot Monitor, Heated Seats...   \n",
            "9                                               None   \n",
            "\n",
            "                                             content  distance  \n",
            "0  Mercedes-Benz C-Class 2020  Coupe Petrol Manua...  0.293558  \n",
            "1  BMW 3 Series 2013 Performance Sedan Electric A...  0.295060  \n",
            "2  BMW 3 Series 2013 LTZ Crossover Hybrid Automat...  0.297940  \n",
            "3  Mercedes-Benz E-Class 2017 Sport Crossover CNG...  0.298353  \n",
            "4  Audi Q5 2020 Touring Hatchback Petrol Automati...  0.300470  \n",
            "5  BMW 5 Series 2018 XSE Van Petrol Automatic mil...  0.301469  \n",
            "6  BMW 3 Series 2016 LX Crossover Hybrid Automati...  0.301566  \n",
            "7  BMW 3 Series 2020 Touring Van CNG Automatic mi...  0.302280  \n",
            "8  Volkswagen Tiguan 2020 Performance Crossover D...  0.305747  \n",
            "9  Mercedes-Benz C-Class 2008 EX Crossover Petrol...  0.305902  \n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
        "user_query = 'a sporty german car with good mileage under $20000'\n",
        "sql = f'''\n",
        "DECLARE q STRING DEFAULT @q;\n",
        "WITH query_vec AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.{REMOTE_MODEL}`,\n",
        "    (SELECT q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_QUERY' AS task_type)\n",
        "  )\n",
        ")\n",
        "SELECT base.* EXCEPT(embedding), distance\n",
        "FROM VECTOR_SEARCH(\n",
        "  TABLE `{PROJECT_ID}.{BQ_DATASET}.{TABLE_EMB}`, 'embedding',\n",
        "  TABLE query_vec, query_column_to_search => 'qvec',\n",
        "  top_k => 10, distance_type => 'COSINE'\n",
        ");\n",
        "'''\n",
        "job = client.query(sql, job_config=bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter('q', 'STRING', user_query)]))\n",
        "#rows = list(job)\n",
        "#print(f\"Results: {len(rows)}\")\n",
        "#for r in rows[:5]:\n",
        "#    print(dict(r))\n",
        "\n",
        "search_results_df = job.to_dataframe()  # Get results as DataFrame\n",
        "\n",
        "\n",
        "# --- Step 3: Display the results ---\n",
        "# This line runs after the BigQuery job is complete\n",
        "print(f\"Found {len(search_results_df)} matching results.\")\n",
        "print(search_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wwO762NS1PCt",
      "metadata": {
        "id": "wwO762NS1PCt"
      },
      "source": [
        "## 7b) Hybrid search: semantic + structured filters\n",
        "Combine **semantic intent** with classic e‑commerce filters (make, price, year, mileage, location). In this example we are searching for a semantic intent \"spacious family SUV with good safety features\" but strictly with a keyword filters min_year = 2024 and price in the range of 10K to 40K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21Ot0hrl3RuU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5123,
          "status": "ok",
          "timestamp": 1758535469280,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "21Ot0hrl3RuU",
        "outputId": "c246b3a0-b5a7-45ce-9f41-fbb1cbfe2ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 matching results.\n",
            "   listing_id   make model  year    price          location condition  \\\n",
            "0         860  Honda  CR-V  2025  33549.0  Avadi, HR, India      good   \n",
            "\n",
            "                                            features  \\\n",
            "0  Adaptive Cruise Control, Alloy Wheels, Apple C...   \n",
            "\n",
            "                                             content  \n",
            "0  Honda CR-V 2025 Trend SUV Petrol Automatic mil...  \n"
          ]
        }
      ],
      "source": [
        "# --- Step 1: Define your search parameters in Python ---\n",
        "# You can easily change these values before running the cell\n",
        "from google.cloud import bigquery\n",
        "import os\n",
        "\n",
        "PROJECT_ID = os.environ.get('PROJECT_ID', 'your-project-id')\n",
        "BQ_DATASET = os.environ.get('BQ_DATASET', \"used_cars\")\n",
        "BQ_LOCATION = os.environ.get('BQ_LOCATION', 'europe-north1')\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)\n",
        "\n",
        "query = 'spacious family SUV with good safety features'\n",
        "make_filter = None        # Set to a string like 'Toyota' to filter, or None to disable\n",
        "min_price_filter = 10000  # Set to an integer, or None to disable\n",
        "max_price_filter = 40000  # Set to an integer, or None to disable\n",
        "min_year_filter = 2024    # Set to an integer, or None to disable\n",
        "location_filter = None    # Set to a string like 'California', or None to disable\n",
        "\n",
        "# Create a dictionary of parameters to pass to BigQuery\n",
        "params = {\n",
        "    \"q\": query,\n",
        "    \"make_filter\": make_filter,\n",
        "    \"min_price_filter\": min_price_filter,\n",
        "    \"max_price_filter\": max_price_filter,\n",
        "    \"min_year_filter\": min_year_filter,\n",
        "    \"location_filter\": location_filter\n",
        "}\n",
        "\n",
        "\n",
        "# --- Step 2: Execute the BigQuery SQL using the 'bigquery' client ---\n",
        "# The results will be saved to the 'search_results_df' DataFrame.\n",
        "sql_query = f\"\"\"\n",
        "-- Generate query embedding\n",
        "WITH query_vec AS (\n",
        "  SELECT ml_generate_embedding_result AS qvec\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{BQ_DATASET}.text_embedding_model`,\n",
        "    (SELECT @q AS content),\n",
        "    STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_QUERY' AS task_type)\n",
        "  )\n",
        "),\n",
        "\n",
        "-- Perform the vector search to get the top 10 semantic matches\n",
        "semantic_searched_list AS (\n",
        "  SELECT\n",
        "    base.listing_id\n",
        "  FROM VECTOR_SEARCH(\n",
        "    TABLE `{PROJECT_ID}.{BQ_DATASET}.used_cars_search`, 'embedding',\n",
        "    TABLE query_vec, query_column_to_search => 'qvec',\n",
        "    top_k => 10, distance_type => 'COSINE'\n",
        "  )\n",
        "),\n",
        "\n",
        "-- Apply the standard filters to the full table\n",
        "filtered_cars AS (\n",
        "  SELECT * EXCEPT (embedding)\n",
        "  FROM `{PROJECT_ID}.{BQ_DATASET}.used_cars_search`\n",
        "  WHERE (@make_filter IS NULL OR make = @make_filter)\n",
        "    AND (@min_price_filter IS NULL OR price >= @min_price_filter)\n",
        "    AND (@max_price_filter IS NULL OR price <= @max_price_filter)\n",
        "    AND (@min_year_filter IS NULL OR year >= @min_year_filter)\n",
        "    AND (@location_filter IS NULL OR location = @location_filter)\n",
        ")\n",
        "\n",
        "-- Join the filtered results with the semantic search results\n",
        "-- This ensures that the final list contains only cars that match BOTH\n",
        "-- the semantic query AND the structured filters.\n",
        "SELECT\n",
        "  filtered_cars.*\n",
        "FROM filtered_cars\n",
        "INNER JOIN semantic_searched_list\n",
        "  ON filtered_cars.listing_id = semantic_searched_list.listing_id;\n",
        "\"\"\"\n",
        "\n",
        "# Prepare query parameters\n",
        "query_params = []\n",
        "for key, value in params.items():\n",
        "    if key == 'q':\n",
        "        query_params.append(bigquery.ScalarQueryParameter(key, 'STRING', value))\n",
        "    elif key in ['min_price_filter', 'max_price_filter', 'min_year_filter']:\n",
        "        query_params.append(bigquery.ScalarQueryParameter(key, 'INT64', value))\n",
        "    else:  # make_filter, location_filter\n",
        "        query_params.append(bigquery.ScalarQueryParameter(key, 'STRING', value))\n",
        "\n",
        "\n",
        "job_config = bigquery.QueryJobConfig(query_parameters=query_params)\n",
        "job = client.query(sql_query, job_config=job_config)\n",
        "search_results_df = job.to_dataframe()  # Get results as DataFrame\n",
        "\n",
        "\n",
        "# --- Step 3: Display the results ---\n",
        "# This line runs after the BigQuery job is complete\n",
        "print(f\"Found {len(search_results_df)} matching results.\")\n",
        "print(search_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a05fa7d",
      "metadata": {
        "id": "0a05fa7d"
      },
      "source": [
        "## 8) Cleanup (optional)\n",
        "To avoid charges, delete the dataset when done:\n",
        "```\n",
        "bq rm -r -f -d ${PROJECT_ID}:${BQ_DATASET}\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
